
# coding: utf-8

# <div align="right">Python 2.7 Jupyter Notebook</div>

# # Data Exploration: Test your intuition about BSSIDs

# ### Your completion of the notebook exercises will be graded based on your ability to: 
# 
# > **Understand**: Does your pseudo-code and/or comments show evidence that you recall and understand technical concepts?
# 
# > **Apply**: Are you able to execute code, using the supplied examples, that perform the required functionality on supplied or generated data sets? 
# 
# > **Evaluate**: Are you able to interpret the results and justify your interpretation based on the observed data?

# # Notebook introduction
# 
# In this notebook you will examine the WiFi scan dataset that you loaded as a dataset in one of the exercises in Module 1, Notebook 2. You will also use the public dataset from Dartmouth College, [Student Life](http://studentlife.cs.dartmouth.edu/dataset.html), that was introduced in Module 1.
# 
# Before continuing with this notebook, it is important to understand the definition of a [BSSID](http://www.juniper.net/techpubs/en_US/network-director1.1/topics/concept/wireless-ssid-bssid-essid.html). A BSSID (Basic Service Set Identifier) is the  media access control (MAC) address (or physical address) of a wireless access point (WAP). It is generated by combining the 24-bit Organization Unique Identifier (the manufacturer's identity) and the manufacturer's assigned 24-bit identifier for the radio chipset in the WAP. In short, every router has a unique address, which will be utilized in this notebook.
# 
# In an analysis, you will start with an idea which you need to validate. In Video 2 of this module, Arek Stopczynski suggests that you should try to test ideas on yourself first, as this is the easiest way of validating your assumptions about the data generated. As a result of this, you will be able to quickly spot anomalies based on your understanding of your own behavior and patterns. Once you have a functional dataset and hypothesis, you should also start to consider cases where the behaviors of others do not necessarily align to your own.
# 
# Manual functions are used to review the data in many cases. When performing an analysis, you need to validate all your assumptions and be able to logically describe what you want to do before selecting a method of execution. In some cases functions utilized may behave in unexpected ways, and you therefore need to constantly perform checks to ensure that the output values are correct and as expected. Pandas is a tried and tested library with a large following of loyal users, however, some of the other libraries that you come across may not be as well-tested.

# > **Note**: 
# 
# > It is strongly recommended that you save a checkpoint after applying significant changes or completing exercises. This allows you to return the notebook to a previous state should you wish to do so. On the Jupyter menu, select "File", then "Save and Checkpoint" from the dropdown menu that appears.

# #### Load libraries

# In[1]:

from os import path
import pandas as pd


# ## 1. Dataset exploration
# 
# #### 1.1 Load data
# To start the process, load a single user's data. For this example you will start with the first recordset, u00.

# In[2]:

# Load the data for a specific user
dataset_path = '../data/dartmouth/wifi/'
user00 = pd.read_csv(path.join(dataset_path, 'wifi_u00.csv'))


# In[3]:

# Display the head.
user00.head(5)


# #### 1.2 Review data definitions (if any)

# The table below provides some definitions for the dataset, which can aid you in better understanding the data.
# 
# Each row represents a WiFi access point seen by a user’s phone. There are four columns in the the provided dataset:
# 
# | Column  | Description |
# | ------------- | ------------- |
# | time | Timestamp of the observation (epochtime format). |
# | BSSID | Unique ID of WiFi access point (MAC address of the hardware). |
# | freq | The frequency on which the access point operates. |
# | level | The strength of the signal. |
# 
# > **Note**:
# 
# > * Epochtime format can be parsed with the Pandas, "to_datetime" function as demonstrated in M1_NB2, section 1.1.
# 
# The first example will only look at the BSSID, while subsequent examples will also look at the timestamp. Students who have worked with BSSIDs previously will notice the lack of an SSID, the network name. This was removed by the Dartmouth researchers prior to the release of the dataset due to institutional security concerns. While it could be argued that this is one of the most useful pieces of information, our analysis does not require this feature.

# #### 1.3 Check for missing values
# You can use the Pandas "count" method to provide a quick overview of the entries in each column that contain values (non-empty). These entries can then be compared with the total number of rows in the dataset. 

# In[4]:

print 'Number values (non-empty records) for each column:'
print user00.count()

print '\n'
print ('Overall number of rows:\n{}'.format(len(user00)))


# Since the columns all contain 446110 records, there are no missing values. So far so good!
# 
# <br>
# <div class="alert alert-info">
# <b>Exercise 1 Start.</b>
# </div>
# 
# ### Instructions
# 
# > Can you recall where you would use the Pandas "info()" and "describe()" functions from Module 1 notebook 2? Use the Pandas libraries to provide the output for each of the functions in the provided cells below. The syntax should be:
# 
# >   `dataset.function()`
# 
# > where "dataset" is the dataset you are analysing (user00 in this case), and "function" is the method or function you wish to apply (either "info" or "describe").

# In[5]:

# Your answer here. (Pandas info)
user00.info()


# In[6]:

# Your answer here. (Pandas describe)
user00.describe()


# <br>
# <div class="alert alert-info">
# <b>Exercise 1 End.</b>
# </div>
# 
# > **Exercise complete**:
#     
# > This is a good time to "Save and Checkpoint".

# #### 1.4 Data validation
# As you can see from the first few lines of the data, the epochtime format is not very useful when trying to review datetimes. In the cell below we use the Pandas "to_datetime()" function to create a new variable, called readable_time, which has the epochtime converted into something humans can understand.
# Panda's default output from to_datetime is in units of milliseconds, which we wish to change to seconds. To use seconds instead, we supply the optional argument, "unit='s' ", to produce the desired output.

# In[7]:

# Repeat the function from section 1.1 to review the contents of the "time" column.
user00.head(3)


# In[8]:

readable_time = pd.to_datetime(user00.time, unit='s')
readable_time.head(5)


# You can use the 'print' command to display the maximum and minimum times in our new dataset. Notice that by adding .min() or .max() after readable_time, Python will apply the method to find these values, and print them in place of {}, which we use for string formatting. The .format function takes as many arguments as there are {}'s, so in this case, 2.

# In[9]:

# Manual review.
print 'Existing times range between: {} and {}'.format(readable_time.min(), readable_time.max())


# In[10]:

# Pandas describe function.
readable_time.describe()


# Next, we use the Pandas value_counts method to find the counts of unique values for observed frequencies in our converted dataset, readable_time. The full syntax for the value_counts method is:
# > `series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)`

# In[11]:

# Use the pandas value_count method to review observed frequencies.
f_counts = pd.value_counts(user00['freq'])
f_counts.head(10)


# You can review the other columns in the dataset, and explore any of the other features, based on the information you have been provided with.

# In[12]:

f_counts2 = pd.value_counts(user00['level'])
f_counts2.head(10)


# In[13]:

f_counts3 = pd.value_counts(user00['time'])
f_counts3.head(10)


# <br>
# <div class="alert alert-info">
# <b>Exercise 2 Start.</b>
# </div>
# 
# ### Instructions
# > Assume for the sake of the exercise, that u00 refers to a dataset created based on your activities.
# 
# > 1. Use the Pandas “value_count” method, demonstrated in section 1.4 with observed frequencies, to review the observations per BSSID ("user00['BSSID']"), and indicate which access point corresponds to your home location.
# 
# > 2. Add a comment to provide your justification for this choice of access point.
# 
# > 3. Provide a brief description of one or two other use cases where your justification in question 2 would be invalid. Think about the locations where you spend most of your time and what other kinds of behaviors you would expect in a large-scale experiment.

# In[14]:

# Your answer here.
f_counts4 = pd.value_counts(user00['BSSID'])
f_counts4.head(10)


# As coded in M1_NB2, the format is series.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)
# The access point correspnding to my home location should be f8:1e:df:fd:4a:4b appearing 12996 times on a descending order ranking made of the value_counts function and we asked to isolate the top 10 most frequently-occurring elements. The most frequnetly used AP should be mine, since I am not using other APs in the vicinity. We can verify it at home by using the commandprompt in windows using the function "netsh wlan show all".
# I am running it at home where I have my own access point. Using a common AP with a common router in a work environment or a local Starbucks, I would have hard time to distinguish my use and the frequency of my accesses vs other users. We would think that in large scale experiements, the localization of people using shared routers or APs would be difficult to isolate and it would be difficult to figure out if they are working together, just sharing a broadband without caring of the presence of each other or interacting and meeting physically together. Besides, distinguishing the nature of the device between desktops, laptops, smartphones or tablets could be important to interpret the data and as far as I know, such a count would not allow to identify the nature of the devices used to connect to the Wlan using the same router. In the same approach, hard to define if users present in the same group or area are using other APs while they could interact with our target users and if so, which ones, since it sounds like there is a lot of BSSIDs in a vicinity with very similar value counts (in our example, between 1000 and 3000 counts).

# <br>
# <div class="alert alert-info">
# <b>Exercise 2 End.</b>
# </div>
# 
# > **Exercise complete**:
#     
# > This is a good time to "Save and Checkpoint".

# ## 2. Submit your notebook
# 
# Please make sure that you:
# - Perform a final "Save and Checkpoint";
# - Download a copy of the notebook in ".ipynb" format to your local machine using "File", "Download as", and "IPython Notebook (.ipynb)", and
# - Submit a copy of this file to the online campus.

# In[15]:

# Check function result from http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.Series.value_counts.html
f_counts4.value_counts(normalize=False, sort=True, ascending=False, bins=None, dropna=True)


# In[16]:

user00 = pd.read_csv(path.join(dataset_path, 'wifi_u00.csv'))


# In[17]:

user00Me = user00.loc[user00['BSSID'] == 'f8:1e:df:fd:4a:4b']


# In[18]:

print user00Me


# In[19]:

readable_time_User00Me = pd.to_datetime(user00Me.time, unit='s')


# In[20]:

readable_time_User00Me.head(15)


# In[21]:

print 'Existing times range between: {} and {}'.format(readable_time_User00Me.min(), readable_time_User00Me.max())


# In[ ]:



